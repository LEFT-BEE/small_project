{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "수치해석project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPpTIl0fcmGUifr6qJaH7pq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEFT-BEE/small_project/blob/main/%EC%88%98%EC%B9%98%ED%95%B4%EC%84%9Dproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69_V3WN2mX9Y"
      },
      "source": [
        "Adaboost \n",
        "1. 각 weak 모델에서 학습할 데이터 선택\n",
        "2. 모든 데이터의 가중치 초기화\n",
        "3. 1회 학습 후 예측 오류(error)계산, 가중치(a)계산, 가중치(D)갱신\n",
        "4. 반복 회수별로 가중치 갱신\n",
        "5. 모든 모델이 위의 단계를 수행할때 까지 반복\n",
        "\n",
        "가중치(D) : 모든 train 데이터에 적용(초기값 동일)\n",
        "\n",
        "오류(e) : 오류데이터 / 전체 학습데이터 , 각 모델의 오류\n",
        "\n",
        "모델별 가중치(a) : ln((1-e) / e) / 2 , 오류를 기반으로 계산\n",
        "\n",
        "예측이 맞을 경우 -> $D_i^{t+1} = \\frac {D_i^{t} \\times e^{-a} }{Sum(D)} $\n",
        "\n",
        "예측이 틀린 경우 -> $D_i^{t+1} = \\frac {D_i^{t} \\times e^{a} }{Sum(D)} $\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rtSWDYz_PRR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_hastie_10_2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\"\"\" HELPER FUNCTION: GET ERROR RATE =========================================\"\"\"\n",
        "def get_error_rate(pred, Y):\n",
        "    return sum(pred != Y) / float(len(Y))\n",
        "\n",
        "\"\"\" HELPER FUNCTION: PRINT ERROR RATE =======================================\"\"\"\n",
        "def print_error_rate(err):\n",
        "    print ('Error rate: Training: %.4f - Test: %.4f' % err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn4s5z3J_WWi"
      },
      "source": [
        "\"\"\" HELPER FUNCTION: GENERIC CLASSIFIER =====================================\"\"\"\n",
        "def generic_clf(Y_train, X_train, Y_test, X_test, clf):\n",
        "    clf.fit(X_train,Y_train)\n",
        "    pred_train = clf.predict(X_train)\n",
        "    pred_test = clf.predict(X_test)\n",
        "    return get_error_rate(pred_train, Y_train), \\\n",
        "           get_error_rate(pred_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-UklgQm_X8u"
      },
      "source": [
        "\"\"\" ADABOOST IMPLEMENTATION =================================================\"\"\"\n",
        "def adaboost_clf(Y_train, X_train, Y_test, X_test, M, clf):\n",
        "    n_train, n_test = len(X_train), len(X_test)\n",
        "    # Initialize weights\n",
        "    w = np.ones(n_train) / n_train\n",
        "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
        "    \n",
        "    for i in range(M):\n",
        "        # Fit a classifier with the specific weights\n",
        "        clf.fit(X_train, Y_train, sample_weight = w)\n",
        "        pred_train_i = clf.predict(X_train)\n",
        "        pred_test_i = clf.predict(X_test)\n",
        "        # Indicator function\n",
        "        miss = [int(x) for x in (pred_train_i != Y_train)]\n",
        "        # Equivalent with 1/-1 to update weights\n",
        "        miss2 = [x if x==1 else -1 for x in miss]\n",
        "        # Error\n",
        "        err_m = np.dot(w,miss) / sum(w)\n",
        "        # Alpha\n",
        "        alpha_m = 0.5 * np.log( (1 - err_m) / float(err_m))\n",
        "        # New weights\n",
        "        w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2]))\n",
        "        # Add to prediction\n",
        "        pred_train = [sum(x) for x in zip(pred_train, \n",
        "                                          [x * alpha_m for x in pred_train_i])]\n",
        "        pred_test = [sum(x) for x in zip(pred_test, \n",
        "                                         [x * alpha_m for x in pred_test_i])]\n",
        "              \n",
        "    pred_train, pred_test = np.sign(pred_train), np.sign(pred_test)\n",
        "    print(\"pred_train : \" , pred_train , \"pred_test : \" , pred_test)\n",
        "    # Return error rate in train and test set\n",
        "    return get_error_rate(pred_train, Y_train), \\\n",
        "           get_error_rate(pred_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzuv-a3A_f4L"
      },
      "source": [
        "\"\"\" PLOT FUNCTION ===========================================================\"\"\"\n",
        "def plot_error_rate(er_train, er_test):\n",
        "    df_error = pd.DataFrame([er_train, er_test]).T\n",
        "    df_error.columns = ['Training', 'Test']\n",
        "    plot1 = df_error.plot(linewidth = 3, figsize = (8,6),\n",
        "            color = ['lightblue', 'darkblue'], grid = True)\n",
        "    plot1.set_xlabel('Number of iterations', fontsize = 12)\n",
        "    plot1.set_xticklabels(range(0,450,50))\n",
        "    plot1.set_ylabel('Error rate', fontsize = 12)\n",
        "    plot1.set_title('Error rate vs number of iterations', fontsize = 16)\n",
        "    plt.axhline(y=er_test[0], linewidth=1, color = 'red', ls = 'dashed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCG_EV5p3neh"
      },
      "source": [
        "\"\"\" MAIN SCRIPT =============================================================\"\"\"\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    # Read data\n",
        "    #Hastie et al.에서 사용 된 2 진 분류를위한 데이터를 생성합니다.10 개의 피쳐는\n",
        "    # 표준 독립적 인 가우시안이며 타겟 y은 다음에 의해 정의됩니다.\n",
        "    #12000천개의 임의 데이터\n",
        "    x, y = make_hastie_10_2()\n",
        "    df = pd.DataFrame(x)\n",
        "    df['Y'] = y\n",
        "\n",
        "    # Split into training and test set\n",
        "    train, test = train_test_split(df, test_size = 0.2)\n",
        "    X_train, Y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
        "    X_test, Y_test = test.iloc[:,:-1], test.iloc[:,-1]\n",
        "    \n",
        "    # Fit a simple decision tree first\n",
        "    clf_tree = DecisionTreeClassifier(max_depth = 1, random_state = 1)\n",
        "    er_tree = generic_clf(Y_train, X_train, Y_test, X_test, clf_tree)\n",
        "    \n",
        "    # Fit Adaboost classifier using a decision tree as base estimator\n",
        "    # Test with different number of iterations\n",
        "    er_train, er_test = [er_tree[0]], [er_tree[1]]\n",
        "  \n",
        "    for i in range(10 , 30):    \n",
        "        print(i-9,\"번째 epoch\")\n",
        "        er_i = adaboost_clf(Y_train, X_train, Y_test, X_test, i, clf_tree)\n",
        "        print_error_rate(er_i)\n",
        "        er_train.append(er_i[0])\n",
        "        er_test.append(er_i[1])\n",
        "    \n",
        "    # Compare error rate vs number of iterations\n",
        "    plot_error_rate(er_train, er_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k1wIwM1806cH"
      },
      "source": [
        "x, y = make_hastie_10_2()\n",
        "len(x)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}