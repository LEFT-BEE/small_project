{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "수치해석project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMBFra5AhUFp2/tFb5jGtvB",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/LEFT-BEE/small_project/blob/main/%EC%88%98%EC%B9%98%ED%95%B4%EC%84%9Dproject.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "69_V3WN2mX9Y"
      },
      "source": [
        "Adaboost \n",
        "1. 각 weak 모델에서 학습할 데이터 선택\n",
        "2. 모든 데이터의 가중치 초기화\n",
        "3. 1회 학습 후 예측 오류(error)계산, 가중치(a)계산, 가중치(D)갱신\n",
        "4. 반복 회수별로 가중치 갱신\n",
        "5. 모든 모델이 위의 단계를 수행할때 까지 반복\n",
        "\n",
        "가중치(D) : 모든 train 데이터에 적용(초기값 동일)\n",
        "\n",
        "오류(e) : 오류데이터 / 전체 학습데이터 , 각 모델의 오류\n",
        "\n",
        "모델별 가중치(a) : ln((1-e) / e) / 2 , 오류를 기반으로 계산\n",
        "\n",
        "예측이 맞을 경우 -> $D_i^{t+1} = \\frac {D_i^{t} \\times e^{-a} }{Sum(D)} $\n",
        "\n",
        "예측이 틀린 경우 -> $D_i^{t+1} = \\frac {D_i^{t} \\times e^{a} }{Sum(D)} $\n",
        "\n",
        "강분류기 = 이전단계의 약분류기 + $W_t \\times H_t$\n",
        "$H(x) = sign(\\alpha_1h_1(x) + \\alpha_2h_2(x) ... \\alpha_Nh_N(x)$\n",
        "\n",
        "즉 약한 분류기가 여러번 약점보완을 통해 강력한 분류기가된다.\n",
        "\n",
        "### 20181512 한승진\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7rtSWDYz_PRR"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import make_hastie_10_2\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "def get_error_rate(pred, Y):\n",
        "    return sum(pred != Y) / float(len(Y))\n",
        "\n",
        "\n",
        "def print_error_rate(err):\n",
        "    print ('Error rate: Training: %.4f - Test: %.4f' % err)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oaEQOPegq3v8"
      },
      "source": [
        "error_rate = 예측실패한 데이터의수 / 전체데이터의수"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hn4s5z3J_WWi"
      },
      "source": [
        "def generic_clf(Y_train, X_train, Y_test, X_test, clf):\n",
        "    clf.fit(X_train,Y_train)\n",
        "    pred_train = clf.predict(X_train)\n",
        "    pred_test = clf.predict(X_test)\n",
        "    return get_error_rate(pred_train, Y_train), get_error_rate(pred_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-UklgQm_X8u"
      },
      "source": [
        "def adaboost_clf(Y_train, X_train, Y_test, X_test, M, clf):\n",
        "    n_train, n_test = len(X_train), len(X_test)\n",
        "\n",
        "    # 가중치 초기화\n",
        "    w = np.ones(n_train) / n_train\n",
        "    pred_train, pred_test = [np.zeros(n_train), np.zeros(n_test)]\n",
        "    \n",
        "    for i in range(M):\n",
        "        clf.fit(X_train, Y_train, sample_weight = w)\n",
        "        pred_train_i = clf.predict(X_train)\n",
        "        pred_test_i = clf.predict(X_test)\n",
        "\n",
        "        # Indicator function\n",
        "        miss = [int(x) for x in (pred_train_i != Y_train)]\n",
        "        miss2 = [x if x==1 else -1 for x in miss]\n",
        "\n",
        "        # Error\n",
        "        err_m = np.dot(w,miss) / sum(w)\n",
        "        # Alpha\n",
        "        alpha_m = 0.5 * np.log( (1 - err_m) / float(err_m))\n",
        "        # New weights\n",
        "        w = np.multiply(w, np.exp([float(x) * alpha_m for x in miss2]))\n",
        "\n",
        "        # 이부분은 copy and paste하였습니다 zip함수의 유용성을 꺠닫게 되었네요\n",
        "        pred_train = [sum(x) for x in zip(pred_train, \n",
        "                                          [x * alpha_m for x in pred_train_i])]\n",
        "        pred_test = [sum(x) for x in zip(pred_test, \n",
        "                                         [x * alpha_m for x in pred_test_i])]\n",
        "    #예측값들 sign함수로 이진분류해주었다.\n",
        "    pred_train, pred_test = np.sign(pred_train), np.sign(pred_test)\n",
        "\n",
        "    # Return error rate in train and test set\n",
        "    return get_error_rate(pred_train, Y_train),get_error_rate(pred_test, Y_test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9xy2302th3u"
      },
      "source": [
        "Adaboost Algorithm (is not copy and paste)\n",
        "\n",
        "1. 가중치를 초기화 해준다 : \n",
        "$w_i = 1/N , i = 1,2,...,N$\n",
        "\n",
        "2. $G_m(x)$를 학습시킨다 , 이떄 $G_m(x)$는 sklearn의 Decision_tree classifer를 가져와 사용하였다.\n",
        "\n",
        "3. 학습한 결과의 Total  error를 찾고 이는 Amount of Say를 결정한다 \n",
        "\n",
        "  $err_m =\\frac{\\sum_{i=1}^{t+1} w_i I(y_i \\neq G_m(x_i)))}{\\sum_{i=1}^N w_i}$\n",
        "\n",
        "  $\\alpha = log((1-err_m) / err_m) $\n",
        "\n",
        "4. 예측이 틀린 경우의 가중치를 업데이트 해준다\n",
        "  $w_i \\leftarrow w_i \\cdot exp [ \\alpha_m \\cdot I(y_i \\neq G_m(x_i))] $\n",
        "\n",
        "  cf)가중치의 경우 논문에서는 두가지 경우로 나누어 가중치를 업데이트하는 방식이 달랐는데 어떤 케이스는 틀린부분의 케이스 만을 업데이트 하는 방식도 있다.. \n",
        "\n",
        "5. 학습한 분류 결과의 합을 sign함수를 통해 이진분류값으로 바꾼다 \n",
        "\n",
        "  $Output G(x) = sign[\\sum_{m=1}^M \\alpha_m G_m(x)]$\n",
        "\n",
        "### 20181512 한승진\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzuv-a3A_f4L"
      },
      "source": [
        "def plot_error_rate(er_train, er_test , mystring):\n",
        "    df_error = pd.DataFrame([er_train, er_test]).T\n",
        "    df_error.columns = ['Training', 'Test']\n",
        "    plot1 = df_error.plot(linewidth = 3, figsize = (8,6),\n",
        "            color = ['lightblue', 'darkblue'], grid = True)\n",
        "    plot1.set_xlabel('Number of iterations', fontsize = 12)\n",
        "    plot1.set_ylabel('Error rate', fontsize = 12)\n",
        "    plot1.set_title(mystring, fontsize = 16)\n",
        "    plt.axhline(y=er_test[0], linewidth=1, color = 'red', ls = 'dashed')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eCG_EV5p3neh"
      },
      "source": [
        "\"\"\" =================================TEST CASE 1 : RANDOM SCATTER DATA =================================\"\"\"\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    #Hastie et al.에서 사용 된 2 진 분류를위한 데이터를 생성합니다.10 개의 피쳐는\n",
        "    # 표준 독립적 인 가우시안이며 타겟 y은 다음에 의해 정의됩니다.\n",
        "    #12000천개의 임의 데이터\n",
        "    x, y = make_hastie_10_2()\n",
        "    df = pd.DataFrame(x)\n",
        "    #dataframe에 label축 추가\n",
        "    df['Y'] = y\n",
        "\n",
        "    # 편리한 train_test_split 모듈을 사용해 train과 test를 나눈다.\n",
        "    train, test = train_test_split(df, test_size = 0.2)\n",
        "    X_train, Y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
        "    X_test, Y_test = test.iloc[:,:-1], test.iloc[:,-1]\n",
        "    \n",
        "    # decisiontree는 모듈을 이용하였습니다.\n",
        "    #adaboost tree 모델생성\n",
        "    clf_tree = DecisionTreeClassifier(max_depth = 2, random_state = 1)\n",
        "    er_tree = generic_clf(Y_train, X_train, Y_test, X_test, clf_tree)\n",
        "    \n",
        "    er_train, er_test = [er_tree[0]], [er_tree[1]]\n",
        "  \n",
        "    for i in range(10 , 100):    \n",
        "        print(i-9,\"번째 epoch\")\n",
        "        er_i = adaboost_clf(Y_train, X_train, Y_test, X_test, i , clf_tree)\n",
        "        print_error_rate(er_i)\n",
        "        er_train.append(er_i[0])\n",
        "        er_test.append(er_i[1])\n",
        "    \n",
        "    # Compare error rate vs number of iterations\n",
        "    plot_error_rate(er_train, er_test , \"Error rate , TEST CASE 1\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2MLmPdsfI0In"
      },
      "source": [
        "\"\"\" ==========================TEST CASE 2 : SKLEARN - CANCER DATA=================================\"\"\"\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "data = load_breast_cancer()\n",
        "#data는 유방암 분류 데이터 셋\n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    x = data.data\n",
        "    y = data.target\n",
        "\n",
        "    df = pd.DataFrame(x)\n",
        "    #dataframe에 label축 추가\n",
        "    df['Y'] = y\n",
        "\n",
        "    # 편리한 train_test_split 모듈을 사용해 train과 test를 나눈다.\n",
        "    train, test = train_test_split(df, test_size = 0.2)\n",
        "    X_train, Y_train = train.iloc[:,:-1], train.iloc[:,-1]\n",
        "    X_test, Y_test = test.iloc[:,:-1], test.iloc[:,-1]\n",
        "\n",
        "    clf_tree = DecisionTreeClassifier(max_depth = 2, random_state = 1)\n",
        "    er_tree = generic_clf(Y_train, X_train, Y_test, X_test, clf_tree)\n",
        "\n",
        "\n",
        "    for i in range(100 , 105):    \n",
        "        print(i-99,\"번째 epoch\")\n",
        "        er_i = adaboost_clf(Y_train, X_train, Y_test, X_test, i, clf_tree)\n",
        "        print_error_rate(er_i)\n",
        "        er_train.append(er_i[0])\n",
        "        er_test.append(er_i[1])\n",
        "    \n",
        "    # Compare error rate vs number of iterations\n",
        "    plot_error_rate(er_train, er_test , \"Error rate , TEST CASE 2\")\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6W0TDVLRLXo"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}